# LLM settings
GOOGLE_API_KEY=your_gemini_api_key_here
# OPENAI_API_KEY=your_openai_api_key_here (optional)
LLM_MODEL=gemini-2.0-flash  # Model for text generation
EMBEDDING_MODEL=models/text-embedding-004  # Model for embeddings
DEFAULT_LLM_PROVIDER=gemini  # Change to 'openai' to use OpenAI

# Database settings
DB_PATH=memory.db
VECTOR_DB_TYPE=chroma  # Options: chroma, faiss
VECTOR_DB_PATH=vector_db
EMBEDDING_DIMENSION=768

# Memory settings
MAX_CONTEXT_TOKENS=8000
QUALITY_THRESHOLD=0.6
DAYS_THRESHOLD=180
CHUNK_SIZE=3
CHUNK_OVERLAP=1

# Token budgets (must sum to 1.0)
ROLLING_SUMMARY_BUDGET=0.3
SPECIFIC_MEMORY_BUDGET=0.4
INSIGHT_BUDGET=0.1
CONVERSATION_HISTORY_BUDGET=0.2

# Application settings
BATCH_SIZE=10
PROCESSING_THREADS=4
LOG_LEVEL=INFO
# LOG_FILE=logs/insightengine.log  # Uncomment to enable file logging

# Debug settings
# VERBOSE_EMBEDDINGS=true  # Uncomment for verbose embedding logs
# DEBUG_EMBEDDINGS=true    # Uncomment for detailed embedding debugging